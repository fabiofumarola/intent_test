{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for intent classifier model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.utils import load_data\n",
    "\n",
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = '../dataset/train.csv'\n",
    "test_file_path = '../dataset/test.csv'\n",
    "df_train = load_data(train_file_path)\n",
    "df_test = load_data(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import INTENT_CLSF_STOPWORDS\n",
    "from src.utils import clean_sentences\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "INPUT_CLEAN_POLICY = '^ a-z A-Z 0-9 @#'\n",
    "INPUT_LEMMATIZER = nltk.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned_questions = clean_sentences(\n",
    "    sentences=df_train['question'],\n",
    "    stopwords=INTENT_CLSF_STOPWORDS,\n",
    "    clean_policy=INPUT_CLEAN_POLICY,\n",
    "    lemmatizer=INPUT_LEMMATIZER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cleaned_questions = clean_sentences(\n",
    "    sentences=df_test['question'],\n",
    "    stopwords=INTENT_CLSF_STOPWORDS,\n",
    "    clean_policy=INPUT_CLEAN_POLICY,\n",
    "    lemmatizer=INPUT_LEMMATIZER\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import create_tokenizer, save_tokenizer, load_tokenizer\n",
    "from src.utils import get_words_max_length, encode_sentences, pad_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer can be created from scratch or loaded from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tokenizer = create_tokenizer(train_cleaned_questions, \n",
    "#                                   filters='!\"#$%&()*+,-./:;<=>?[\\]^_`{|}~')\n",
    "input_tokenizer = load_tokenizer('../model_params/input_tokenizer.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(input_tokenizer.word_index) + 1\n",
    "WORDS_MAX_LENGTH = get_words_max_length(train_cleaned_questions)\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (VOCAB_SIZE, WORDS_MAX_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_sentences = encode_sentences(input_tokenizer, \n",
    "                                           train_cleaned_questions)\n",
    "test_encoded_sentences = encode_sentences(input_tokenizer, \n",
    "                                          test_cleaned_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_sentences = pad_sentences(train_encoded_sentences,\n",
    "                                       WORDS_MAX_LENGTH)\n",
    "test_padded_sentences = pad_sentences(test_encoded_sentences,\n",
    "                                      WORDS_MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the output intent string labels\n",
    "Tokenizer for the output (intent label strings) with filter changed so that it does not contain the underscore '_' symbol.\n",
    "\n",
    "Also here, the tokenizer can be created from scratch or loaded form disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import encode_output_labels, one_hot\n",
    "\n",
    "OUTPUT_CLEAN_POLICY = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intent_labels = list(set(df_train['intent']))\n",
    "# output_tokenizer = create_tokenizer(intent_labels, \n",
    "#                                     filters = OUTPUT_CLEAN_POLICY)\n",
    "output_tokenizer = load_tokenizer('../model_params/output_tokenizer.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_output = encode_output_labels(output_tokenizer, df_train['intent'])\n",
    "test_encoded_output = encode_output_labels(output_tokenizer, df_test['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_one_hot = one_hot(train_encoded_output)\n",
    "test_output_one_hot = one_hot(test_encoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training set in train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(train_padded_sentences,\n",
    "                                                  train_output_one_hot,\n",
    "                                                  shuffle=True,\n",
    "                                                  test_size=0.2)\n",
    "\n",
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_OF_INTENT_CLASSES = len(output_tokenizer.word_index)\n",
    "\n",
    "def create_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 128, input_length=max_length, trainable=False))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NR_OF_INTENT_CLASSES, activation = \"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(vocab_size=VOCAB_SIZE, \n",
    "                     max_length=WORDS_MAX_LENGTH)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('trained_weights'):\n",
    "    os.makedirs('trained_weights')\n",
    "filename = 'trained_weights/intent_classifier_{epoch:04d}-{val_loss:.8f}.h5'\n",
    "tensorboard_log_dir = 'tb_logs'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filename, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             mode='min')\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_log_dir,\n",
    "                          histogram_freq=0,\n",
    "                          update_freq='epoch',\n",
    "                          write_graph=False,\n",
    "                          write_grads=False,\n",
    "                          write_images=False,\n",
    "                          embeddings_freq=0)\n",
    "\n",
    "hist = model.fit(train_X, train_Y, \n",
    "                 epochs=30, \n",
    "                 batch_size=16, \n",
    "                 validation_data=(val_X, val_Y), \n",
    "                 callbacks=[checkpoint, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(20,5))\n",
    "ax[0].plot(hist.history['loss'], color='red', label='train')\n",
    "ax[0].plot(hist.history['val_loss'], color='green', label='val')\n",
    "ax[1].plot(hist.history['accuracy'], color='red', label='train')\n",
    "ax[1].plot(hist.history['val_accuracy'], color='green', label='val')\n",
    "ax[0].set_ylabel('categorical_crossentropy')\n",
    "ax[1].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../model_params/intent_classifier_0012-1.05701441.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'How are you?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess the input and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = clean_sentence(input_text, \n",
    "                            stopwords=INTENT_CLSF_STOPWORDS,\n",
    "                            clean_policy=INPUT_CLEAN_POLICY,\n",
    "                            lemmatizer=INPUT_LEMMATIZER)\n",
    "\n",
    "encoded_text = encode_sentences(input_tokenizer, clean_text)\n",
    "\n",
    "# Check for unknown words\n",
    "if [] in encoded_text:\n",
    "    encoded_text = list(filter(None, encoded_text))\n",
    "\n",
    "out = np.array(encoded_text).reshape(1, len(encoded_text))\n",
    "x = pad_sentences(out, WORDS_MAX_LENGTH)\n",
    "\n",
    "pred = model.predict_proba(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions range from 0 to NR_OF_INTENT_CLASSES - 1, while output labels are indexed starting from 1\n",
    "intent_index = np.argmax(pred) + 1  \n",
    "confidence = round(np.max(pred), 3)\n",
    "predicted_intent = output_tokenizer.index_word[intent_index]\n",
    "print(\"Predicted intent '{}' with confidence {:>4.3f}\".format(predicted_intent, confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x=test_padded_sentences,\n",
    "                                          y=test_output_one_hot)\n",
    "print('Test loss = {}'.format(test_loss))\n",
    "print('Test accuracy = {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = model.evaluate(x=train_padded_sentences,\n",
    "                                          y=train_output_one_hot)\n",
    "print('Train loss = {}'.format(train_loss))\n",
    "print('Train accuracy = {}'.format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict_proba(test_padded_sentences)\n",
    "labels_pred = np.array(list(map(lambda i: output_tokenizer.index_word[i+1], np.argmax(test_pred, axis=1))))\n",
    "labels_true = np.array(list(map(lambda i: output_tokenizer.index_word[i], test_encoded_output.flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = list(output_tokenizer.word_index.keys())\n",
    "cm = confusion_matrix(y_true=labels_true, \n",
    "                      y_pred=labels_pred, \n",
    "                      labels=intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "df_cm = pd.DataFrame(cm, intents, intents)\n",
    "sn.set(font_scale=0.5) # for label size\n",
    "sn.heatmap(df_cm)\n",
    "\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "ax.set_ylabel(\"True label\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intent_test",
   "language": "python",
   "name": "intent_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
